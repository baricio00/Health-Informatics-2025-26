{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ciEBGMI5alog",
        "6vWzbwC_pr-7",
        "44FLh9uKSq-V",
        "Q4f4yPryPp8X"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/baricio00/Health-Informatics-2025-26/blob/main/Copy_of_Lab_IV_SMHD_25_26_TBC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<font size=\"6\">Statistical Models for Healthcare Data</font>**\n",
        "\n",
        "**<font size=\"5\">MSc in Health Informatics - UniSR - A.Y. 2025-2026</font>**\n",
        "\n",
        "Prof. Lara Cavinato - Dott. Vittorio Torri\n",
        "\n",
        "---\n",
        "\n",
        "<font size=\"4\">Lab IV - Generalized Linear Models</font>"
      ],
      "metadata": {
        "id": "v213oWQNY_4e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "ciEBGMI5alog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.options.display.float_format = '{:.2f}'.format"
      ],
      "metadata": {
        "id": "V4tZOCOQanB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "B56Kp3nQectc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "XBmIG3NMcLCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "0qNen7Ljcx3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm"
      ],
      "metadata": {
        "id": "1_MvRLcN_No-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1234)"
      ],
      "metadata": {
        "id": "WcaQ5G3rJ5JR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats"
      ],
      "metadata": {
        "id": "gEbCEGDUUmxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "6vWzbwC_pr-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Ias1u5HLpuR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/hf_dataset_lab_iv.csv')"
      ],
      "metadata": {
        "id": "KrcL7EH9YktP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "IXvXjHqHauKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_vars = ['anaemia', 'diabetes', 'high_blood_pressure',  'sex',  'smoking',  'DEATH_EVENT']\n",
        "num_vars = ['age', 'creatinine_phosphokinase', 'ejection_fraction', 'platelets', 'serum_creatinine', 'serum_sodium', 'bmi', 'time', 'rehospitalizations']"
      ],
      "metadata": {
        "id": "qz4KsntemxVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Binary Logistic Regression"
      ],
      "metadata": {
        "id": "44FLh9uKSq-V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to build a model to classify patients as dead or survived during follow-up: binary classification."
      ],
      "metadata": {
        "id": "BPAZvVG-lCEF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use a logistic regression model, which models the probability of the positive class (death) in the following way, where $x_1, ..., x_p$ are the input variables.\n",
        "\n",
        "We might be interested in having a model that consider additional variables that might be useful"
      ],
      "metadata": {
        "id": "xTsQWu5MlLPV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "P(y = 1 | x) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p)}}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "SNZToGSJk8mc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have the $\\beta$ multiplying the predictors. Generalized linear regression is an extended linear regression"
      ],
      "metadata": {
        "id": "ciO1jYFfV8Qm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "xPcrzyWG6TL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[['age', 'bmi', 'anaemia', 'creatinine_phosphokinase', 'diabetes', 'high_blood_pressure', 'platelets', 'serum_creatinine', 'serum_sodium', 'sex', 'smoking', 'ejection_fraction', 'time', 'rehospitalizations']]\n",
        "y = df['DEATH_EVENT'].astype(int) # Explicitly convert boolean DEATH_EVENT to int (True=1, False=0)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1234)\n",
        "\n",
        "train_index = X_train.index\n",
        "test_index = X_test.index"
      ],
      "metadata": {
        "id": "LnCDwYJHTgp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start using all numerical variables"
      ],
      "metadata": {
        "id": "qcHNyWzdla_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_1 = X_train[num_vars]\n",
        "X_test_1 = X_test[num_vars]\n",
        "\n",
        "X_train_1 = sm.add_constant(X_train_1)\n",
        "X_test_1 = sm.add_constant(X_test_1)\n",
        "\n",
        "logit_model = sm.Logit(y_train, X_train_1).fit()\n",
        "\n",
        "print(logit_model.summary())"
      ],
      "metadata": {
        "id": "QrhNMlk-16wG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_1 = X_train[num_vars]\n",
        "X_test_1 = X_test[num_vars]\n",
        "\n",
        "X_train_1 = sm.add_constant(X_train_1)\n",
        "X_test_1 = sm.add_constant(X_test_1)\n",
        "\n",
        "logit_model = sm.Logit(y_train, X_train_1).fit()\n",
        "\n",
        "print(logit_model.summary())"
      ],
      "metadata": {
        "id": "-aCiTJE6Ssoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If I see \"Optimization terminated successfully\", the optimization feature converge, so there is no need to add a constant.\n",
        "\n",
        "\"Log-Likelihood\", \"LL-Null\" (no input variable) and \"LLR p-value\" should be very low, so it means I'm doing something useful.\n",
        "\n",
        "The only difference is that we have a \"z\" value but we can ignore it. If I have P>|z| higher than 50%, maybe the variable is useless.\n",
        "\n",
        "What's important is the interpretation. I could have $\\beta_{age}$, but what I need is the exponent of each coefficient to interpret and understand the effect on the ouput in my model."
      ],
      "metadata": {
        "id": "UodJSjaGX8mg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default statsmodels uses the Newton-Raphson iterative optimization method to maximize the likelihood, but other methods can be specified"
      ],
      "metadata": {
        "id": "EeX64cY71vgm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Statsmodels compute the pseudo R^2 statistics using the McFadden's definition:\n",
        "\n",
        "$$pseudo_{R^2} = 1 - \\frac{LL}{LL_{Null}}$$\n",
        "\n",
        "It takes values from 0 to 1 and it indicates the goodness of the model, but it's not the primary metric used to evaluate LR models"
      ],
      "metadata": {
        "id": "61bg1FXgw8sJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Odds Ratios"
      ],
      "metadata": {
        "id": "6jJbqFPnA1tI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a logistic model, the effect of the coefficient is different from a linear regression model. A k-unit increase in $x_j$ increases the risk by a factor of $exp(k \\cdot \\hat{\\beta_j})$. Odds ratios are defined as:\n",
        "\n",
        "$$\n",
        "OR_j = exp(\\hat{\\beta_j})\n",
        "$$"
      ],
      "metadata": {
        "id": "2qOnScyFBFKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coef = logit_model.params\n",
        "odds_ratios = np.exp(coef) # e^coef\n",
        "\n",
        "conf = logit_model.conf_int() # get the confidence intervals\n",
        "conf.columns = ['2.5%', '97.5%']\n",
        "conf = np.exp(conf)  # Exponentiate the betas' CIs to get ORs' CIs\n",
        "\n",
        "or_summary = pd.DataFrame({\n",
        "    \"Coefficient\": coef,\n",
        "    \"Odds Ratio\": odds_ratios,\n",
        "    \"2.5% CI OR\": conf['2.5%'],\n",
        "    \"97.5% CI OR\": conf['97.5%']\n",
        "})\n",
        "\n",
        "or_summary = or_summary.drop('const')\n",
        "# if odds ratio is 1.05, there is an increase of 5% on the output\n",
        "# every unit increasing in ef, having an odds ratio of 0.96, I'm reducing by 4% the prob of dying\n",
        "# having an odds ratio of 1.00, means that I'm not adding anything to the output\n",
        "# the serum creatinine = 1.51, adds much info, but have CI = 0.75, so we can't fully rely on this information\n",
        "\n",
        "print(or_summary)"
      ],
      "metadata": {
        "id": "0B3Y8DFwA3pA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort by odds ratio for better visualization\n",
        "or_summary = or_summary.sort_values(by=\"Odds Ratio\", ascending=False)\n",
        "\n",
        "# The 'const' column was already dropped in a previous cell (0B3Y8DFwA3pA)\n",
        "# so this line is redundant and causes a KeyError.\n",
        "# or_summary = or_summary.drop('const')\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, len(or_summary) * 0.6))\n",
        "\n",
        "# Plot the OR as points with confidence intervals\n",
        "ax.errorbar(or_summary['Odds Ratio'], or_summary.index,\n",
        "            xerr=[or_summary['Odds Ratio'] - or_summary['2.5% CI OR'], or_summary['97.5% CI OR'] - or_summary['Odds Ratio']],\n",
        "            fmt='o', color='darkblue', ecolor='lightgray', elinewidth=3, capsize=4)\n",
        "\n",
        "# Add a vertical line at OR = 1 (meaning no effect)\n",
        "ax.axvline(1, color='red', linestyle='--')\n",
        "\n",
        "ax.set_xlabel(\"Odds Ratio (log scale)\")\n",
        "ax.set_title(\"Forest Plot of Odds Ratios with 95% CI\")\n",
        "#ax.set_xscale(\"log\")  # Log scale is sometimes useful for better visualization\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bdwVNZig0Arf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "platelets and creatine_phosphokinase are useless, but \"rehospitalizations\" is an issue because we can't understand if it's a protective effect. The age is slightly positive and above the red line, so it has small moderate effect of increasing the death event condition -> it's useful"
      ],
      "metadata": {
        "id": "K8hqcdIrbGnp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion Matrix"
      ],
      "metadata": {
        "id": "kr7pPzqXATxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "30UdjbOQ3ycF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred_prob = logit_model.predict(X_test_1)\n",
        "# we try to measure on the test set the performance of the model\n",
        "# looking in the elements, I have probabilities as output.\n",
        "# We might want turn them into binary values, because I'm treating categorical variables\n",
        "# we set a threshold to define when the value must be 1 or 0"
      ],
      "metadata": {
        "id": "_8w02RtK0wSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred_prob"
      ],
      "metadata": {
        "id": "z4ec-y9lEtHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic regression is a probabilistic model, i.e. it outputs a probability of belonging to the \"positive\" class, but how do we turn this into a binary output? We need to define a threshold"
      ],
      "metadata": {
        "id": "vvtXXckp1pF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.5\n",
        "y_test_pred_class = (y_test_pred_prob > threshold).astype(int)\n",
        "# how to define the threshold? Here's it's 0.5"
      ],
      "metadata": {
        "id": "QDPNGdh0Exzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred_class"
      ],
      "metadata": {
        "id": "yJ1JqV0kE4Tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Confusion Matrix on Test Set:\")\n",
        "print(confusion_matrix(y_test.astype(int), y_test_pred_class))"
      ],
      "metadata": {
        "id": "UI1fOJ1YUh3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember the interpretation of a binary confusion matrix:\n",
        "\n",
        "[  TN    FP  ]\n",
        "\n",
        "[  FN    TP  ]\n",
        "\n",
        "TN = True Negatives,\n",
        "TP = True Positives,\n",
        "FP = False Positives,\n",
        "FN = False Negatives"
      ],
      "metadata": {
        "id": "ZZSVA8hw2J5a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With a better visualization:"
      ],
      "metadata": {
        "id": "cHZIOeScqBJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_test_pred_class)\n",
        "# it's the way to understand what my model is doing\n",
        "\n",
        "class_names = ['Survived', 'Dead']\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uvyzUja1pk8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AUC"
      ],
      "metadata": {
        "id": "6t56rgWxASPc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I want to have a model that is not influenced by a threshold"
      ],
      "metadata": {
        "id": "Sev7rsTaeZRi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Receiver-Operating-Characteristic Curve (ROC Curve) plots the FPR vs TPR at varying the classification threshold from 0 to 1, where\n",
        "\n",
        "$$TPR = \\frac{TP}{TP+FN} (= Sensitivity = Recall)$$\n",
        "\n",
        "$$FPR = \\frac{FP}{FP+TN}$$"
      ],
      "metadata": {
        "id": "fXXMAvxSouKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok but TPR and FPR depend on classification threshold, because they change.\n",
        "\n",
        "I draw a line on the plot, that defines the threshold for the AUC"
      ],
      "metadata": {
        "id": "_5kakJ6hex4D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ideal point is (0,1), which minimizes the FPR and maximizes the TPR"
      ],
      "metadata": {
        "id": "-oOlWKz6pLus"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Area Under the Reveiver-Operating-Characteristic Curve (AUC-ROC or simply AUC) is a measure of goodness of the model that is not influences by the choice of a classification threshold"
      ],
      "metadata": {
        "id": "GnA3n0fVpQ0Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's first compute the TPR and FPR from the current confusion matrix, i.e. with threshold=0.5. We will use them later to compare"
      ],
      "metadata": {
        "id": "mS_7jZ2l6WeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tn, fp, fn, tp = cm.ravel()\n",
        "tpr_original = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "fpr_original = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
        "print(f'FPR={fpr_original}, TPR={tpr_original}')"
      ],
      "metadata": {
        "id": "DZ2MOPd26ZPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's plot the ROC curve"
      ],
      "metadata": {
        "id": "E-0WJlkd6lx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# computes the roc curve as a set of points (fpr, tpr)\n",
        "fpr, tpr, _ = roc_curve(y_test, y_test_pred_prob) # the third elements that it returns are the thresholds. roc_curve(target, probabilities)\n",
        "# _ is for the threshold\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Plot the ROC curve\n",
        "plt.plot(fpr, tpr, color='blue', label=f\"ROC Curve\")\n",
        "\n",
        "# Plot the diagonal line representing random chance\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--', label=\"Chance\")\n",
        "\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve for Binary Classification\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9Wk-ZcRU3F4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If I set a threshold at (0;0) I'm classifying everything as positive.\n",
        "\n",
        "The line is useful, because if the AUC is under the line, I know that the model is doing very bad.\n",
        "\n",
        "I want a model that is as near as possible to (0;1). The maximum area could be 1, as it's a rectangle"
      ],
      "metadata": {
        "id": "MgiXGePZf1la"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "And compute the area below it"
      ],
      "metadata": {
        "id": "1_I34plw6o0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "auc_score = roc_auc_score(y_test, y_test_pred_prob)\n",
        "print(f\"ROC-AUC Score on Test Set: {auc_score}\")"
      ],
      "metadata": {
        "id": "retBsP9QeJxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accuracy, Precision, Recall/Sensitivity, F1-Score, Specificity"
      ],
      "metadata": {
        "id": "-sUQYEcdARk7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$Accuracy = \\frac{TP+TN}{TP+FP+TN+FN}$$\n",
        "$$Precision = \\frac{TP}{TP+FP}$$\n",
        "$$Recall = Sensitivity = TPR = \\frac{TP}{TP+FN}$$\n",
        "$$\\text{F1-Score} = \\frac{2 \\cdot Precision \\cdot Recall}{Precision + Recall}$$\n",
        "$$Specificity = \\frac{TN}{TN+FP}$$"
      ],
      "metadata": {
        "id": "7uT-Y4G2n3YD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the accuracy is 0.7, the model is working correctly in 70% of the cases.\n",
        "\n",
        "The higher the precision, the lower is the possibility to have mistakes, becuse I have less false positive.\n",
        "\n",
        "The F1-score is between 0 and 1. It's the geometric precision of the model. It's affected on high precision or high recall.\n",
        "\n",
        "The specificity (along with sensitivity) are important in healthcare data. It's the recall of the otehr classes. It's the percentage of people that are correctly flagged as negative in my data. The sensitivity tells how many people are correctly marked as positive"
      ],
      "metadata": {
        "id": "tOWuD2YbhS1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"Classification Report on Test Set:\")\n",
        "print(classification_report(y_test, y_test_pred_class, target_names=['Survived', 'Dead'], digits=4))"
      ],
      "metadata": {
        "id": "nbtAwP9ZUiiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "recall=0.6111 means there are some false negatives"
      ],
      "metadata": {
        "id": "smcrv1uhj37L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What about the sensitivity? We can compute it explicitly, but it is already implicitly reported in the classification record..."
      ],
      "metadata": {
        "id": "5-YKFmE53K91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "rgqNrAdHoU0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Choice of the threshold"
      ],
      "metadata": {
        "id": "PYqAh7M8DPdN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using 0.5 as threshold is the most common choice, but it might not be the optimal one, especially in case of class unbalance"
      ],
      "metadata": {
        "id": "_uv3fLGcm0bD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One suggest value is the percentage of negative samples"
      ],
      "metadata": {
        "id": "O2gf7g7mDbKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "candidate_threshold_1 = 1 - df['DEATH_EVENT'].mean() # 1 - % of positive samples"
      ],
      "metadata": {
        "id": "kcqNCkXFDRh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "candidate_threshold_1"
      ],
      "metadata": {
        "id": "h1N52rlqD79W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred_class = (y_test_pred_prob > candidate_threshold_1).astype(int)\n",
        "\n",
        "print(\"Confusion Matrix on Test Set:\")\n",
        "print(confusion_matrix(y_test, y_test_pred_class))"
      ],
      "metadata": {
        "id": "vCao_b_sD9Th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nClassification Report on Test Set:\")\n",
        "print(classification_report(y_test, y_test_pred_class))"
      ],
      "metadata": {
        "id": "TWdx2CuyEDvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see where this threshold ends up on the ROC curve"
      ],
      "metadata": {
        "id": "CpDLeIv63g2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred_class).ravel()\n",
        "\n",
        "tpr_1 = tp / (tp + fn)  # Sensitivity or Recall or TPR\n",
        "fpr_1 = fp / (fp + tn)  # False Positive Rate (FPR)\n",
        "\n",
        "print(f'FPR={fpr_1}, TPR={tpr_1}')"
      ],
      "metadata": {
        "id": "eRtk7-Lr44zN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot ROC Curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='blue', label=f\"ROC Curve\")\n",
        "\n",
        "# Plot the point corresponding to the candidate threshold point\n",
        "plt.scatter(fpr_1, tpr_1, color='orange', s=100, label=f\"Threshold with Proportion of Negative Samples (= {candidate_threshold_1:.2f})\")\n",
        "\n",
        "# Plot the point corresponding to the original threshold point\n",
        "plt.scatter(fpr_original, tpr_original, color='green', s=100, label=f\"Default threshold (thr=0.5)\")\n",
        "\n",
        "# Plot the diagonal line representing random chance\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--', label=\"Chance\")\n",
        "\n",
        "# Labels and legend\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve with Threshold = Proportion of negative samples\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eCvRsIeb4SVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What's better? There is no definitive answer"
      ],
      "metadata": {
        "id": "pFfH42tal1aI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another heuristic is the **maximization** of the **Youden's J index**, which is the *difference between TPR and FPR*"
      ],
      "metadata": {
        "id": "kSlE-c0_5GJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds= roc_curve(y_test, y_test_pred_prob)"
      ],
      "metadata": {
        "id": "s8n45CJrQu9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fpr"
      ],
      "metadata": {
        "id": "vzpZcaGSQ1ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tpr"
      ],
      "metadata": {
        "id": "hnbeOsc6Q2Y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "thresholds"
      ],
      "metadata": {
        "id": "6rT-b5NFQyT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "youden_all = tpr - fpr\n",
        "idx_best = np.argmax(youden_all)\n",
        "best_thr = thresholds[idx_best]\n",
        "best_J = youden_all[idx_best]\n",
        "best_tpr, best_fpr = tpr[idx_best], fpr[idx_best]\n",
        "\n",
        "print(f\"Max Youden's J on ROC: {best_J:.4f} at threshold {best_thr:.4f} \"\n",
        "      f\"(TPR={best_tpr:.4f}, FPR={best_fpr:.4f})\")"
      ],
      "metadata": {
        "id": "AuLorekO5HeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=\"ROC curve\")\n",
        "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\", label=\"Chance\")\n",
        "\n",
        "# % of negative points\n",
        "plt.scatter(fpr_1, tpr_1, s=100, color='orange', label=f\"% of neg samples (thr={candidate_threshold_1:.2f})\")\n",
        "\n",
        "# Original threshold point\n",
        "plt.scatter(fpr_original, tpr_original, color='green', s=100, label=f\"Default threshold (thr=0.5)\")\n",
        "\n",
        "# Maximize Youden's J\n",
        "plt.scatter(best_fpr, best_tpr, s=100, color='red',\n",
        "            label=f\"Max J (thr={best_thr:.2f}, J={best_J:.2f})\")\n",
        "\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q0ONoBmU5Y2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A smaller model"
      ],
      "metadata": {
        "id": "gtljlQKoB3Ac"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: Based on the output of the previous model, try to fit a smaller model and compute its performances"
      ],
      "metadata": {
        "id": "qSdUrS6iB5GY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "SLLCiqMUCU9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiclass logistic regression"
      ],
      "metadata": {
        "id": "3VD6JSEMu8cZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to develop a model to classify HF patients in the three ejection fraction classes we defined in Lab II.\n",
        "\n",
        "Multiclass logistic regression is an extended class of logistic regression"
      ],
      "metadata": {
        "id": "pnd5ntmCsYYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['ef_cat'] = pd.cut(df['ejection_fraction'], bins=[0,40,50, 100], labels=['reduced', 'mildly reduced', 'preserved'])"
      ],
      "metadata": {
        "id": "M_Kb3v-8vALA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['ejection_fraction', 'ef_cat']] # ejection fraction categorized\n",
        "# it's udeful to have a model that predicts this class, as it's difficult to predict\n",
        "# the more classes you have, the more complex the model, so the more is the need to build a model that performs well"
      ],
      "metadata": {
        "id": "0zhgRLqi7vLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "UCFYHo876QCC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A multinomial logistic regression model assumes a baseline class (assume the *K*-th one without loss of generality) and computes a set of coefficients for each other class *k*:\n",
        "\n",
        "$$\n",
        "P(y = k | x) = \\frac{e^{\\beta_{k0} + \\beta_{k1} x_1 + \\beta_{k2} x_2 + \\dots + \\beta_{kp} x_p}}{1 + \\sum_{j=1}^{K-1} e^{\\beta_{j0} + \\beta_{j1} x_1 + \\beta_{j2} x_2 + \\dots + \\beta_{jp} x_p}} \\quad\\text{for }k < K \\\\\n",
        "P(y = K | x) = \\frac{1}{1 + \\sum_{j=1}^{K-1} e^{\\beta_{j0} + \\beta_{j1} x_1 + \\beta_{j2} x_2 + \\dots + \\beta_{jp} x_p}}\n",
        "$$\n",
        "\n",
        "At the denominator we have the sum of each class parameter. We have a set of parameters of each class except one"
      ],
      "metadata": {
        "id": "gz1wIkgv2_Ot"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The multinomial logistic regression model implemented in the *statsmodels* library requires categorical input variables to be *one-hot encoded*\n",
        "\n",
        "We'll have a set of betas for each class. $\\beta_0$ for class 0, $\\beta_1$ for class 1, nd so on."
      ],
      "metadata": {
        "id": "XdEESfgYtOTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "df_encoded = pd.get_dummies(df, columns=cat_vars, drop_first=True, dtype=int)"
      ],
      "metadata": {
        "id": "BSSK0VCjvlOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_encoded"
      ],
      "metadata": {
        "id": "ZpyT-A30vmQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_encoded[['age', 'bmi', 'serum_sodium', 'serum_creatinine', 'diabetes_1', 'sex_Male', 'smoking_1', 'high_blood_pressure_1', 'anaemia_1', 'rehospitalizations']]\n",
        "y = df_encoded['ef_cat']  # Multiclass target variable\n",
        "\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234, stratify=y)"
      ],
      "metadata": {
        "id": "MnLo4CWHvL7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "nR2jteAmTK6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = sm.MNLogit(y_train, X_train) # multinomial logit\n",
        "result = model.fit()\n",
        "\n",
        "print(result.summary())\n",
        "\n",
        "# We have LLR p-value that is very low, meaning that our model contains something very useful\n",
        "# The method decided to take the \"ef_cat=mildly reduced\""
      ],
      "metadata": {
        "id": "x11RwKyxwJlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.params\n",
        "\n",
        "# the classes are replaced with numbers (0 and 1)"
      ],
      "metadata": {
        "id": "CtwRnpiu8J74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model._ynames_map # in this way I get a dictionary with the name of the classes"
      ],
      "metadata": {
        "id": "dBSEKo6BTwhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.exp(result.params).rename(columns={0: 'mildly_reduced OR', 1:'preserved OR'})\n",
        "\n",
        "# we have the odds ratio that are completely different from each other."
      ],
      "metadata": {
        "id": "Bwm3leiFOc3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'model' and 'result' objects are available from previous cells.\n",
        "\n",
        "# Get the actual class names used as keys in the confidence interval DataFrame\n",
        "estimated_class_names = result.conf_int().index.get_level_values(0).unique()\n",
        "\n",
        "fig, axs = plt.subplots(1, len(estimated_class_names), figsize=(6 * len(estimated_class_names), 6))\n",
        "\n",
        "# Ensure axs is iterable even if there's only one subplot\n",
        "if len(estimated_class_names) == 1:\n",
        "    axs = [axs]\n",
        "\n",
        "for i, class_name_str in enumerate(estimated_class_names):\n",
        "    # current_class_params_col_idx corresponds to the integer column index in result.params\n",
        "    # assuming the order in estimated_class_names matches the column order (0, 1, ...)\n",
        "    current_class_params_col_idx = i\n",
        "\n",
        "    coef = result.params.iloc[:, current_class_params_col_idx] # Access by integer position\n",
        "    odds_ratios = np.exp(coef)\n",
        "\n",
        "    # Get confidence intervals for the current class from the result object\n",
        "    conf_raw = result.conf_int()\n",
        "    # Filter for the current class_name_str. result.conf_int() has a MultiIndex.\n",
        "    conf_class_filtered = conf_raw.loc[class_name_str] # Use string name for MultiIndex loc\n",
        "\n",
        "    # Exponentiate the confidence intervals\n",
        "    conf_exp = np.exp(conf_class_filtered)\n",
        "\n",
        "    or_summary = pd.DataFrame({\n",
        "        \"Coefficient\": coef,\n",
        "        \"Odds Ratio\": odds_ratios,\n",
        "        \"2.5% CI OR\": conf_exp.iloc[:, 0], # Access by integer position\n",
        "        \"97.5% CI OR\": conf_exp.iloc[:, 1]  # Access by integer position\n",
        "    })\n",
        "\n",
        "    # Drop the 'const' row for plotting as it's typically not interpreted as an OR\n",
        "    or_summary = or_summary.drop('const')\n",
        "\n",
        "    # Sort by odds ratio for better visualization\n",
        "    or_summary = or_summary.sort_values(by=\"Odds Ratio\", ascending=False)\n",
        "\n",
        "    # Plot on the corresponding subplot\n",
        "    ax = axs[i]\n",
        "    ax.errorbar(or_summary['Odds Ratio'], or_summary.index,\n",
        "                xerr=[or_summary['Odds Ratio'] - or_summary['2.5% CI OR'], or_summary['97.5% CI OR'] - or_summary['Odds Ratio']],\n",
        "                fmt='o', color='darkblue', ecolor='lightgray', elinewidth=3, capsize=4)\n",
        "\n",
        "    # Add a vertical line at OR = 1 (meaning no effect)\n",
        "    ax.axvline(1, color='red', linestyle='--')\n",
        "    ax.set_xlabel(\"Odds Ratio (log scale)\")\n",
        "    ax.set_title(f\"Forest Plot for {class_name_str} vs. Reduced (95% CI)\")\n",
        "    ax.set_xscale(\"log\") # Log scale is essential for better visualization of ORs\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_Q2dTJH18XiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test set evaluation"
      ],
      "metadata": {
        "id": "_2dMNLMf6Z71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred_prob = result.predict(X_test)  # Returns probabilities for each class\n",
        "\n",
        "y_test_pred_prob.rename(model._ynames_map, axis='columns', inplace=True)\n",
        "\n",
        "y_test_pred_class = y_test_pred_prob.idxmax(axis=1) #for each sample, assign the class with maximum probability"
      ],
      "metadata": {
        "id": "Zt7bX6-n5qnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred_prob"
      ],
      "metadata": {
        "id": "oQf143ILZOiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#example\n",
        "print(y_test_pred_prob.iloc[0])\n",
        "print(y_test_pred_class.iloc[0])"
      ],
      "metadata": {
        "id": "sB9U5ppr5vHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "zAAsf_FBSwEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred_class"
      ],
      "metadata": {
        "id": "zeI24rijVntR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "\n",
        "cm = confusion_matrix(y_test, y_test_pred_class, labels=list(model._ynames_map.values()))\n",
        "\n",
        "class_names = model._ynames_map.values()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "10TeMM6e0DcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_test_pred_class))"
      ],
      "metadata": {
        "id": "cmwcR8co0Uy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a multiclass context, the ROC-AUC can be computed per class with a one-vs-all approach"
      ],
      "metadata": {
        "id": "VI8shPgJ_FeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Map y_test (multiclass categorical strings) to numerical labels (0, 1, 2)\n",
        "class_mapping = {class_name: idx for idx, class_name in enumerate(model._ynames_map.values())}\n",
        "y_test_numerical = y_test.map(class_mapping)\n",
        "\n",
        "# Rename columns of y_test_pred_prob to match numerical labels (0, 1, 2)\n",
        "y_test_pred_prob_numerical = y_test_pred_prob.rename(columns=class_mapping)\n",
        "\n",
        "# Compute ROC AUC for each class (one-vs-all)\n",
        "roc_auc_scores = {}\n",
        "for i in (y_test_pred_prob_numerical.columns):\n",
        "    # For one-vs-all, treat class i as positive (1) and all others as negative (0)\n",
        "    # y_test_numerical == i will produce a boolean series, which sklearn accepts\n",
        "    roc_auc = roc_auc_score(y_test_numerical == i, y_test_pred_prob_numerical.loc[:, i])\n",
        "    roc_auc_scores[model._ynames_map[i]] = roc_auc # Map back to original class names for display\n",
        "\n",
        "# Output the ROC AUC scores\n",
        "for class_name, auc in roc_auc_scores.items():\n",
        "    print(f'ROC AUC for {class_name}: {auc:.2f}')"
      ],
      "metadata": {
        "id": "K4e_pKF2--Ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "An aggregate ROC-AUC can be computed in different ways"
      ],
      "metadata": {
        "id": "A63wXA82_0w7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = y_test.map({'reduced': 0, 'mildly reduced': 1, 'preserved': 2})\n",
        "y_test_pred_prob.rename(columns={'reduced': 0, 'mildly reduced': 1, 'preserved': 2}, inplace=True)\n",
        "\n",
        "roc_auc_micro = roc_auc_score(y_test, y_test_pred_prob, average='micro', multi_class='ovr')\n",
        "print(f'Micro-average ROC AUC: {roc_auc_micro:.2f}')\n",
        "\n",
        "roc_auc_micro = roc_auc_score(y_test, y_test_pred_prob, average='macro', multi_class='ovr')\n",
        "print(f'Macro-average ROC AUC: {roc_auc_micro:.2f}')\n",
        "\n",
        "roc_auc_micro = roc_auc_score(y_test, y_test_pred_prob, average='weighted', multi_class='ovr')\n",
        "print(f'Weighted-average ROC AUC: {roc_auc_micro:.2f}')"
      ],
      "metadata": {
        "id": "noHPH-Ur_4ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{array}{|c|c|c|c|}\n",
        "\\hline\n",
        "\\textbf{Aspect} & \\textbf{Macro-Averaging} & \\textbf{Micro-Averaging} & \\textbf{Weighted Averaging} \\\\\n",
        "\\hline\n",
        "\\textbf{Calculation} & \\text{Average of individual class metrics} & \\text{Aggregated metrics across all classes} & \\text{Average of class metrics weighted by class size} \\\\\n",
        "\\hline\n",
        "\\textbf{Class Weighting} & \\text{Treats all classes equally} & \\text{Larger classes have more influence} & \\text{Larger classes influence the average more} \\\\\n",
        "\\hline\n",
        "\\textbf{Performance Insight} & \\text{Insight into performance of each class} & \\text{Overall performance across the entire dataset} & \\text{Balanced evaluation considering class sizes} \\\\\n",
        "\\hline\n",
        "\\textbf{Sensitivity} & \\text{Sensitive to class imbalance} & \\text{More robust to class imbalance} & \\text{Moderately sensitive to class imbalance} \\\\\n",
        "\\hline\n",
        "\\textbf{Use Cases} & \\text{Class-specific performance} & \\text{Overall model performance} & \\text{Balanced performance in imbalanced datasets} \\\\\n",
        "\\hline\n",
        "\\end{array}\n"
      ],
      "metadata": {
        "id": "MaNpDfJYArJ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\text{Precision}_{\\text{micro}} = \\frac{\\sum_{i=1}^{C} \\text{TP}_i}{\\sum_{i=1}^{C} (\\text{TP}_i + \\text{FP}_i)}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{Recall}_{\\text{micro}} = \\frac{\\sum_{i=1}^{C} \\text{TP}_i}{\\sum_{i=1}^{C} (\\text{TP}_i + \\text{FN}_i)}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{F1}_{\\text{micro}} = 2 \\times \\frac{\\text{Precision}_{\\text{micro}} \\times \\text{Recall}_{\\text{micro}}}{\\text{Precision}_{\\text{micro}} + \\text{Recall}_{\\text{micro}}}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "BDa_gcPYaO2m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use macro when:\n",
        "\n",
        "*  You care about per-class behavior, and you want to treat all classes equally, regardless of their frequency.\n",
        "\n",
        "*  You want to evaluate model fairness across all classes, including rare or underrepresented ones.\n",
        "\n",
        "*  You're dealing with imbalanced data, and you want to make sure small classes still matter in the evaluation.\n",
        "\n",
        "*  You want to highlight weaknesses in your modelâ€™s performance on rare classes.\n",
        "\n",
        "\n",
        "\n",
        "Use micro when:\n",
        "\n",
        "*  You don't care about classes individually.\n",
        "\n",
        "* You only care about total prediction quality.\n",
        "\n",
        "* You are working with highly multilabel settings (many labels per sample).\n",
        "\n",
        "* You want one simple number for \"How many labels did I guess right?\".\n",
        "\n",
        "Use weighted when:\n",
        "\n",
        "* You do care about per-class behavior.\n",
        "\n",
        "* You want a summary that adjusts for imbalance but still thinks per-class.\n",
        "\n",
        "* You have imbalanced classes, but you still want per-class precision/recall insight."
      ],
      "metadata": {
        "id": "kSehOv6SiWbJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Change baseline class"
      ],
      "metadata": {
        "id": "19YXnDAi2CLv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manually encoding the target variable allows us to change the order of the numerical labels and consequently change the variable used as base"
      ],
      "metadata": {
        "id": "n-KufCN592KX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_encoded = pd.get_dummies(df, columns=cat_vars, drop_first=True, dtype=int)\n",
        "df_encoded['ef_cat'] = pd.Categorical(df['ef_cat'], categories=['mildly reduced', 'preserved', 'reduced'], ordered=True)"
      ],
      "metadata": {
        "id": "FKiDyndE1D2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_encoded[['age', 'bmi', 'serum_sodium', 'serum_creatinine', 'diabetes_1', 'sex_Male', 'smoking_1', 'high_blood_pressure_1', 'anaemia_1']]\n",
        "y = df_encoded['ef_cat']  # Multiclass target variable\n",
        "\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234, stratify=y)"
      ],
      "metadata": {
        "id": "Jfs_Y9eF2VBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = sm.MNLogit(y_train, X_train)\n",
        "result = model.fit()\n",
        "\n",
        "print(result.summary())"
      ],
      "metadata": {
        "id": "QiboF4it2ZQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model._ynames_map"
      ],
      "metadata": {
        "id": "qdb7F4XGJryt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.exp(result.params).rename(columns={0: 'preserved OR', 1:'reduced OR'})"
      ],
      "metadata": {
        "id": "A0Ks2EspRtQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Poisson Regression"
      ],
      "metadata": {
        "id": "XnMoLfZE6rD6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want a model for the number of reshospitalizations in 90 days. This is an integer count, that can be modelled with a Poisson variable."
      ],
      "metadata": {
        "id": "bPYJzv40ldeZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$ Y \\sim \\text{Poisson}(\\lambda) \\quad \\text{where} \\quad \\lambda = e^{\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_p X_p} $$\n"
      ],
      "metadata": {
        "id": "H2T6dqXymJVw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "E2OlRnhC-00T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_encoded = pd.get_dummies(df, columns=cat_vars, drop_first=True, dtype=int)"
      ],
      "metadata": {
        "id": "WhmIH_FqACR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_encoded"
      ],
      "metadata": {
        "id": "UIk8opRVAAjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_vars = ['age', 'sex_Male', 'bmi', 'ejection_fraction', 'serum_sodium', 'serum_creatinine', 'creatinine_phosphokinase',\n",
        "              'diabetes_1', 'smoking_1', 'high_blood_pressure_1', 'anaemia_1']\n",
        "\n",
        "\n",
        "X = df_encoded[input_vars]\n",
        "y = df_encoded['rehospitalizations']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1234)\n",
        "\n",
        "train_index = X_train.index\n",
        "test_index = X_test.index\n",
        "\n",
        "X_train_1 = X_train[input_vars]\n",
        "X_test_1 = X_test[input_vars]\n",
        "X_train_1 = sm.add_constant(X_train_1)\n",
        "X_test_1 = sm.add_constant(X_test_1)\n",
        "\n",
        "# Fit Poisson regression model\n",
        "poisson_model = sm.GLM(y_train, X_train_1, family=sm.families.Poisson()).fit()\n",
        "print(poisson_model.summary())"
      ],
      "metadata": {
        "id": "VJqXRou2-kxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rate Ratios"
      ],
      "metadata": {
        "id": "xPWLLKa4Ahhc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly to logistic regression models, in poisson models there are Rate Ratios (RR) instead of Odds Ratios (OR). A k-unit increase in $x_j$ increases the count by a factor of $exp(k \\cdot \\hat{\\beta_j})$. Rate ratios are defined as:\n",
        "\n",
        "$$\n",
        "RR_j = exp(\\hat{\\beta_j})\n",
        "$$"
      ],
      "metadata": {
        "id": "JJA2XQAEBRN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = poisson_model.params\n",
        "conf = poisson_model.conf_int()\n",
        "conf['Rate Ratio'] = np.exp(params)\n",
        "conf.columns = ['2.5%', '97.5%', 'Rate Ratio']\n",
        "conf['2.5%'] = np.exp(conf['2.5%'])\n",
        "conf['97.5%'] = np.exp(conf['97.5%'])\n",
        "print(conf)"
      ],
      "metadata": {
        "id": "qPiu2f_H_A7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf = conf.sort_values(by=\"Rate Ratio\", ascending=False)\n",
        "conf['variable'] = conf.index\n",
        "\n",
        "conf = conf[conf.variable != 'const']\n",
        "\n",
        "\n",
        "# Plot\n",
        "fig, ax = plt.subplots(figsize=(8, len(conf) * 0.6))\n",
        "ax.errorbar(conf['Rate Ratio'], conf.index,\n",
        "            xerr=[conf['Rate Ratio'] - conf['2.5%'], conf['97.5%'] - conf['Rate Ratio']],\n",
        "            fmt='o', color='darkblue', ecolor='lightgray', elinewidth=3, capsize=4)\n",
        "ax.axvline(1, color='red', linestyle='--')\n",
        "ax.set_xlabel(\"Rate Ratio (log scale)\")\n",
        "ax.set_title(\"Forest Plot of Rate Ratios with 95% CI\")\n",
        "ax.set_xscale(\"log\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tlZYBwrcAmTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test set evaluation"
      ],
      "metadata": {
        "id": "I8eFKb5ZFAtP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the parameter $\\lambda$ of the Poisson distribution is also its mean, to compute the output on a new observation the $\\hat{\\lambda}$ for the that observation is used, i.e.\n",
        "\n",
        "$$\\hat{y} = \\hat{\\lambda} = exp(\\beta_0 + \\beta_1 \\cdot x_1 + ... + \\beta_p \\cdot x_p)$$"
      ],
      "metadata": {
        "id": "DBCgIhZZnMSO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2$$\n",
        "$$ \\text{MAE} = \\frac{1}{n} \\sum_{i=1}^n |y_i - \\hat{y}_i|\n",
        "$$\n"
      ],
      "metadata": {
        "id": "9WZWkNvBlyeN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MSE emphasizes larger errors more, while MAE provides an average error magnitude."
      ],
      "metadata": {
        "id": "1sYfpNH6l4PD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO compute MSE and MAE on the test set"
      ],
      "metadata": {
        "id": "pwbHmgmRAr4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "id": "Md8gHe4Hmoei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.round(y_pred)"
      ],
      "metadata": {
        "id": "hdfGml5aq_Bx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feedback"
      ],
      "metadata": {
        "id": "Q_tweh8yNQOZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please leave a feedback on this lab through [this form](https://forms.office.com/e/WuD3i9GtgH) (estimated 2 minutes)"
      ],
      "metadata": {
        "id": "V2aZyAaNNRml"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "743cab5b"
      },
      "source": [
        "# Task\n",
        "Create two forest plots to visualize the odds ratios and their 95% confidence intervals for the 'mildly reduced' and 'preserved' classes from the multinomial logistic regression model, using the 'reduced' class as the baseline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bec4045"
      },
      "source": [
        "## Plot Multinomial Odds Ratios\n",
        "\n",
        "### Subtask:\n",
        "Extract coefficients and confidence intervals for 'mildly reduced' and 'preserved' classes from the multinomial logistic regression model, calculate odds ratios and their confidence intervals, and then generate two forest plots to visualize these odds ratios for each class against the baseline 'reduced' class.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9bea40e"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   Coefficients and their 95% confidence intervals were successfully extracted from the multinomial logistic regression model for the 'mildly reduced' and 'preserved' classes, using the 'reduced' class as the baseline.\n",
        "*   Odds ratios (ORs) and their corresponding 95% confidence intervals were computed for each predictor variable within both the 'mildly reduced' and 'preserved' classes.\n",
        "*   Two distinct forest plots were generated to visually represent these odds ratios and their 95% confidence intervals, providing a clear comparison for the 'mildly reduced' and 'preserved' heart failure phenotypes against the 'reduced' baseline.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The generated forest plots will enable a straightforward visual identification of predictor variables that significantly influence the odds of belonging to the 'mildly reduced' or 'preserved' classes compared to the 'reduced' class (i.e., confidence intervals not crossing 1).\n",
        "*   The next step should involve interpreting these forest plots to identify key demographic, clinical, or echocardiographic factors that are strong discriminators between the three heart failure phenotypes.\n"
      ]
    }
  ]
}